# 1. IMPORT LIBRARIES
import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import TruncatedSVD
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.metrics import (
    accuracy_score, f1_score, classification_report,
    confusion_matrix, roc_curve, auc
)
from IPython.display import display

# =============================================================================
# 2. LOAD DATASET
# =============================================================================
df = pd.read_csv("/content/fake_news_realistic_dataset_v2.csv")  # adjust filename
print("Dataset shape:", df.shape)
display(df.head())

# =============================================================================
# 3. DATA PREPROCESSING
# =============================================================================

# 3.1 Drop duplicates & missing
df.drop_duplicates(inplace=True)
df.dropna(subset=['title', 'content', 'label'], inplace=True)

# 3.2 Text cleaning
def clean_text(text):
    text = text.lower()
    text = re.sub(r'http\S+|www\S+', ' ', text)          # remove URLs
    text = re.sub(r'[^a-z\s]', ' ', text)                # letters only
    text = re.sub(r'\s+', ' ', text).strip()             # extra spaces
    return text

df['text'] = (df['title'] + ' ' + df['content']).apply(clean_text)

# =============================================================================
# 4. EXPLORATORY DATA ANALYSIS (EDA)
# =============================================================================

# 4.1 Class balance
plt.figure(figsize=(6,4))
sns.countplot(x='label', data=df)
plt.title("Fake vs Real distribution")
plt.xticks([0,1], ['Real','Fake'])
plt.show()

# 4.2 Text length distributions
df['word_count'] = df['text'].apply(lambda x: len(x.split()))
df['char_count'] = df['text'].apply(len)

fig, axes = plt.subplots(1,2, figsize=(12,4))
sns.histplot(df['word_count'], ax=axes[0], kde=True)
axes[0].set_title("Word Count Distribution")
sns.histplot(df['char_count'], ax=axes[1], kde=True)
axes[1].set_title("Character Count Distribution")
plt.show()

# 4.3 Correlation heatmap (for numerical features)
num_cols = ['word_count','char_count']
corr = df[num_cols + ['label']].corr()
plt.figure(figsize=(5,4))
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.title("Feature Correlations")
plt.show()

# =============================================================================
# 5. FEATURE ENGINEERING
# =============================================================================

# 5.1 TF-IDF Vectorization
tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))
X_tfidf = tfidf.fit_transform(df['text'])

# 5.2 Dimensionality Reduction (optional)
svd = TruncatedSVD(n_components=300, random_state=42)
X_reduced = svd.fit_transform(X_tfidf)

# 5.3 Combine with other numerical features
X_num = df[['word_count','char_count']].values
scaler = StandardScaler()
X_num_scaled = scaler.fit_transform(X_num)

# Final feature matrix
X = np.hstack([X_reduced, X_num_scaled])
y = df['label'].values

# =============================================================================
# 6. TRAIN-TEST SPLIT
# =============================================================================
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# =============================================================================
# 7. MODEL BUILDING & HYPERPARAMETER TUNING
# =============================================================================

# 7.1 Define models
lr = LogisticRegression(max_iter=1000, random_state=42)
rf = RandomForestClassifier(n_estimators=200, random_state=42)

# Fit the Logistic Regression model
lr.fit(X_train, y_train)

# 7.2 Grid Search for RF (example)
param_grid = {
    'n_estimators': [100,200],
    'max_depth': [None, 10, 20],
}
grid_rf = GridSearchCV(
    rf, param_grid, cv=3, scoring='f1', n_jobs=-1
)
grid_rf.fit(X_train, y_train)
print("Best RF params:", grid_rf.best_params_)

# 7.3 Ensemble (Voting)
ensemble = VotingClassifier(
    estimators=[
        ('lr', lr), # Use the already fitted lr model
        ('rf', grid_rf.best_estimator_)
    ],
    voting='hard'
)
ensemble.fit(X_train, y_train)

# =============================================================================
# 8. MODEL EVALUATION
# =============================================================================
models = {
    'Logistic Regression': lr, # Now lr is fitted
    'Random Forest': grid_rf.best_estimator_,
    'Ensemble Voting': ensemble
}

for name, model in models.items():
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    print(f"\n{name} â€“ Acc: {acc:.4f}, F1: {f1:.4f}")
    print(classification_report(y_test, y_pred, target_names=['Real','Fake']))

    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(4,4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Real','Fake'], yticklabels=['Real','Fake'])
    plt.title(f"{name} Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

    # ROC Curve
    if hasattr(model, "predict_proba"):
        probs = model.predict_proba(X_test)[:,1]
        fpr, tpr, _ = roc_curve(y_test, probs)
        roc_auc = auc(fpr, tpr)
        plt.figure(figsize=(5,4))
        plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.3f}")
        plt.plot([0,1],[0,1],'--')
        plt.title(f"{name} ROC Curve")
        plt.xlabel("FPR")
        plt.ylabel("TPR")
        plt.legend()
        plt.show()
